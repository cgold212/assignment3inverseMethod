{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgold212/assignment3inverseMethod/blob/main/chenCopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9igFl3eWgxJs"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as T\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsdtngu_hcz7"
      },
      "outputs": [],
      "source": [
        "trfm = transforms.Compose([transforms.Resize((200,200)),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.ToTensor()]) \n",
        "\n",
        "data  = datasets.StanfordCars(root='Stanford_cars_dataset' , transform= None,  download = True)\n",
        "test_data  = datasets.StanfordCars(root='Stanford_cars_dataset' , split= 'test', transform= None,  download = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG8M1FpnaUOt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "23c879e0-9ef5-4584-8dc3-82eb3f6d77c5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9b1799121b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# create dirs for new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ordered_stanford_dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ordered_stanford_dataset/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ordered_stanford_dataset/valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './ordered_stanford_dataset'"
          ]
        }
      ],
      "source": [
        "# load annotations and labels\n",
        "mat_train= loadmat('./Stanford_cars_dataset/stanford_cars/devkit/cars_train_annos.mat')\n",
        "mat_test= loadmat('./Stanford_cars_dataset/stanford_cars/cars_test_annos_withlabels.mat')\n",
        "meta = loadmat('./Stanford_cars_dataset/stanford_cars/devkit/cars_meta.mat')\n",
        "\n",
        "# get classes\n",
        "labels = list()\n",
        "for l in meta['class_names'][0]:\n",
        "    labels.append(l[0].replace('/','').replace(' ','_'))\n",
        "\n",
        "# get train labels\n",
        "train = list()\n",
        "for example in mat_train['annotations'][0]:\n",
        "    label  = labels[example[-2][0][0]-1]\n",
        "    image  = example[-1][0]\n",
        "    class_car= example[4][0][0]\n",
        "    train.append((image, class_car, label))\n",
        "\n",
        "# get test labels\n",
        "test = list()\n",
        "for example in mat_test['annotations'][0]:\n",
        "    label  = labels[example[-2][0][0]-1]\n",
        "    image  = example[-1][0]\n",
        "    class_car= example[4][0][0]\n",
        "    test.append((image, class_car, label))\n",
        "\n",
        "# create dirs for new dataset\n",
        "os.mkdir('./ordered_stanford_dataset')\n",
        "os.mkdir('./ordered_stanford_dataset/train')\n",
        "os.mkdir('./ordered_stanford_dataset/valid')\n",
        "os.mkdir('./ordered_stanford_dataset/test')\n",
        "\n",
        "# get all filenames for train and test\n",
        "imgs_train = os.listdir('./Stanford_cars_dataset/stanford_cars/cars_train')\n",
        "imgs_test = os.listdir('./Stanford_cars_dataset/stanford_cars/cars_test')\n",
        "\n",
        "# create dir for each label in train and test\n",
        "for i in labels:\n",
        "    os.mkdir('./ordered_stanford_dataset/train/'+i)\n",
        "    os.mkdir('./ordered_stanford_dataset/valid/'+i)\n",
        "    os.mkdir('./ordered_stanford_dataset/test/'+i)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se4dc4qcWXUE"
      },
      "outputs": [],
      "source": [
        "# move files from train to specific folder in the new dataset \n",
        "for image in imgs_train:\n",
        "    for annos in train:\n",
        "        img_name = annos[0]\n",
        "        img_label = annos[2]\n",
        "        if image == img_name:\n",
        "            src = './Stanford_cars_dataset/stanford_cars/cars_train/'+image\n",
        "            des = './ordered_stanford_dataset/train/'+img_label+'/'+image\n",
        "            shutil.move(src,des)\n",
        "            break\n",
        "# move files from test to specific folder in the new dataset \n",
        "for image in imgs_test:\n",
        "    for annos in test:\n",
        "        img_name = annos[0]\n",
        "        img_label = annos[2]\n",
        "        if image == img_name:\n",
        "            src = './Stanford_cars_dataset/stanford_cars/cars_test/'+image\n",
        "            des = './ordered_stanford_dataset/test/'+img_label+'/'+image\n",
        "            shutil.move(src,des)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TPY4LPCYNGN"
      },
      "outputs": [],
      "source": [
        "# get valid dataset from train\n",
        "val_part = 0.1\n",
        "for l in labels:\n",
        "    files = os.listdir('./ordered_stanford_dataset/train/'+l)\n",
        "    num_files = len(files)\n",
        "    num_val_files = int(np.floor(num_files * val_part))\n",
        "    if num_val_files > 0:\n",
        "        val_idxs = random.sample(range(0, num_files),num_val_files)   # pick random images for validation\n",
        "        for idx in val_idxs:\n",
        "            src = './ordered_stanford_dataset/train/' + l + '/' + files[idx]\n",
        "            des = './ordered_stanford_dataset/valid/' + l + '/' + files[idx]\n",
        "            shutil.move(src, des)\n",
        "# get valid dataset from test\n",
        "for l in labels:\n",
        "    files = os.listdir('./ordered_stanford_dataset/test/'+l)\n",
        "    num_files = len(files)\n",
        "    num_val_files = int(np.floor(num_files * val_part))\n",
        "    if num_val_files > 0:\n",
        "        val_idxs = random.sample(range(0, num_files),num_val_files)   # pick random images for validation\n",
        "        for idx in val_idxs:\n",
        "            src = './ordered_stanford_dataset/test/' + l + '/' + files[idx]\n",
        "            des = './ordered_stanford_dataset/valid/' + l + '/' + files[idx]\n",
        "            shutil.move(src, des)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_jIFabSLpsz"
      },
      "outputs": [],
      "source": [
        "# get ordered datasets\n",
        "# stats = ((0, 0, 0), (1, 1, 1))\n",
        "trfm = transforms.Compose([\n",
        "                          transforms.Resize((256, 256)),\n",
        "                          T.RandomCrop(size=(100, 100)),\n",
        "                          transforms.RandomHorizontalFlip(0.5),\n",
        "                          #  transforms.ColorJitter(),\n",
        "                          transforms.ToTensor(),\n",
        "                          # transforms.Normalize(*stats, inplace = True)\n",
        "                          ]) \n",
        "trfm_test = transforms.Compose([\n",
        "                          transforms.Resize((256, 256)),\n",
        "                          # T.RandomCrop(size=(128, 128)),\n",
        "                          transforms.RandomHorizontalFlip(0.5),\n",
        "                          #  transforms.ColorJitter(),\n",
        "                          transforms.ToTensor(),\n",
        "                          # transforms.Normalize(*stats, inplace = True)\n",
        "                          ])\n",
        "\n",
        "train_data = datasets.ImageFolder('./ordered_stanford_dataset/train',transform= trfm)\n",
        "val_data = datasets.ImageFolder('./ordered_stanford_dataset/valid',transform= trfm)\n",
        "test_data = datasets.ImageFolder('./ordered_stanford_dataset/test',transform= trfm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmDZPqCiPnVC"
      },
      "outputs": [],
      "source": [
        "print('number of images in train - '+str(len(train_data)))\n",
        "print('number of images in validation - '+str(len(val_data)))\n",
        "print('number of images in test - '+str(len(test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJgKxMZGOnBL"
      },
      "outputs": [],
      "source": [
        "# get data loaders\n",
        "def get_data_loaders(train_data,val_data,test_data,batch_size):\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, \n",
        "                              shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, \n",
        "                              shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, \n",
        "                              shuffle=True, num_workers=2)\n",
        "    \n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-sCuZMriK3_"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_loader, val_loader, test_loader = get_data_loaders(train_data,val_data,test_data,batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vS67UT2jOyW_"
      },
      "outputs": [],
      "source": [
        "# function to show bach images\n",
        "def show(imgs,num2show):\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid((imgs.detach()[:num2show]), nrow=8).permute(1, 2, 0))\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pDtSve0O0vo"
      },
      "outputs": [],
      "source": [
        "# batch_train_images, train_labels = next(iter(train_loader))\n",
        "# show(batch_train_images,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f5y4EaaZAl3"
      },
      "outputs": [],
      "source": [
        "# batch_test_images, test_labels = next(iter(test_loader))\n",
        "# show(batch_test_images,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ4oYq6Tgcje"
      },
      "outputs": [],
      "source": [
        "# batch_val_images, val_labels = next(iter(val_loader))\n",
        "# show(batch_val_images,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KATjE4Z9Rs1U"
      },
      "outputs": [],
      "source": [
        "# train_data.classes[53]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC68azCdqrbK"
      },
      "outputs": [],
      "source": [
        "# len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9jBYyyNo1dj"
      },
      "outputs": [],
      "source": [
        "# val_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_LrRZ8j2Frx"
      },
      "outputs": [],
      "source": [
        "# train_loader.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQCk-9chxsux"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHfMEPm-yr2c"
      },
      "outputs": [],
      "source": [
        "# train function\n",
        "def train(model, train_loader, val_loader, num_epochs, criterion, optimizer, grad_clip = None, checkpoint_path = None):\n",
        "    # print(1)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    train_losses_iter = []\n",
        "    n_iters = 0\n",
        "    model = model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        total_correct = 0\n",
        "        total_instances = 0\n",
        "        for images, labels in train_loader:\n",
        "            n_iters += 1\n",
        "            optimizer.zero_grad()\n",
        "            # print(2)\n",
        "            if torch.cuda.is_available():\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "            # print(3)\n",
        "            one_hot = torch.zeros((64, 196))\n",
        "            one_hot[torch.arange(len(labels)), labels] = 1\n",
        "            # print(one_hot[0,:])\n",
        "            one_hot = one_hot.to(device)\n",
        "            # print(4)\n",
        "            outputs = model(images)\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            # print(5)\n",
        "            # print(outputs.shape)\n",
        "            if outputs.shape[0] == one_hot.shape[0]:\n",
        "              # print(outputs.shape)\n",
        "              loss = criterion(outputs, one_hot)  \n",
        "              loss.backward() \n",
        "\n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "\n",
        "            \n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            train_losses_iter.append(loss.item()/train_loader.batch_size)\n",
        "\n",
        "            # get classifications of the batch\n",
        "            classifications = torch.argmax(outputs, dim=1)\n",
        "            correct_predictions = sum(classifications == labels).item()\n",
        "            total_correct += correct_predictions\n",
        "            total_instances += len(images)\n",
        "            if n_iters % 50 == 0:\n",
        "                print('Iter - %d Train loss - %f'%(n_iters , loss.item()/train_loader.batch_size))\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    images = images.cuda()\n",
        "                    labels = labels.cuda()\n",
        "                outputs = model(images)\n",
        "                outputs = torch.sigmoid(outputs)          \n",
        "                one_hot = torch.zeros((64, 196))\n",
        "                one_hot[torch.arange(len(labels)), labels] = 1\n",
        "                # print(one_hot[0,:])\n",
        "                one_hot = one_hot.to(device)    \n",
        "                if outputs.shape[0] == one_hot.shape[0]:\n",
        "                  # print(outputs.shape)\n",
        "                  loss = criterion(outputs, one_hot)  \n",
        "                  val_loss += loss.item()\n",
        "                  _, predicted = torch.max(outputs.data, 1)\n",
        "                  total += labels.size(0)\n",
        "                  correct += (predicted == labels).sum().item()\n",
        "        cur_train_acc = round(total_correct/total_instances, 3)\n",
        "        train_accuracies.append(cur_train_acc)\n",
        "        train_losses.append(train_loss/train_loader.batch_size)\n",
        "        val_losses.append(val_loss/val_loader.batch_size)\n",
        "        val_accuracies.append(correct/total)\n",
        "        if epoch % 10 == 0:\n",
        "            plot_results_iter(train_losses_iter, val_losses, val_accuracies, train_accuracies)\n",
        "        print('Epoch - %d | train acc - %f%% | val acc - %f%%'%(epoch ,100*cur_train_acc ,100*correct/total))\n",
        "        if (checkpoint_path is not None) and epoch > 0 and epoch % 5 == 0:\n",
        "            torch.save(model.state_dict(), checkpoint_path.format(epoch0))\n",
        "    return train_losses, val_losses, val_accuracies, train_accuracies\n",
        "\n",
        "def plot_results(train_losses, val_losses, val_accuracies):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.plot(train_losses, label='train')\n",
        "    ax1.plot(val_losses, label='val')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax2.plot(np.array(val_accuracies)*100)\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    plt.show()\n",
        "def plot_results_iter(train_losses, val_losses, val_accuracies, train_accuracies):\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.plot(train_losses, label='train')\n",
        "    # ax1.plot(val_losses, label='val')\n",
        "    ax1.set_xlabel('Iterations')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax2.plot(np.array(train_accuracies)*100,label='train')\n",
        "    ax2.plot(np.array(val_accuracies)*100,label='val')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HSSJzuhrRLFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.classes = list(set(dataset.targets))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_sample, anchor_label = self.dataset[idx]\n",
        "        positive_class = anchor_label\n",
        "        negative_class = random.choice([c for c in self.classes if c != positive_class])\n",
        "        positive_index = random.choice([i for i, l in enumerate(self.dataset.targets) if l == positive_class])\n",
        "        negative_index = random.choice([i for i, l in enumerate(self.dataset.targets) if l == negative_class])\n",
        "        positive_sample, positive_label = self.dataset[positive_index]\n",
        "        negative_sample, negative_label = self.dataset[negative_index]\n",
        "        return anchor_sample, positive_sample, negative_sample\n",
        "\n",
        "\n",
        "triplet_dataset = TripletDataset(train_data)\n",
        "batch_size = 200\n",
        "triplet_dataloader = DataLoader(triplet_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "triplet_dataloader1, val_loader, test_loader = get_data_loaders(triplet_dataloader,val_data,test_data,batch_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g41h4relEJF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def train_siamese(model, dataloader, optimizer, criterion, num_epochs, checkpoint_path = None):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print('epoch num: ' ,epoch )\n",
        "        if (checkpoint_path is not None) and epoch > 0 and epoch % 5 == 0:\n",
        "          print(1)\n",
        "          torch.save(model.state_dict(), checkpoint_path.format(epoch))\n",
        "        for i, (anchor_image, positive_image, negative_image) in enumerate(triplet_dataloader):\n",
        "              \n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              print(negative_image.shape)\n",
        "              anchor_image = anchor_image.to(device)            \n",
        "              positive_image = positive_image.to(device)\n",
        "              negative_image = negative_image.to(device)\n",
        "\n",
        "              # Compute the feature representations of the anchor, positive, and negative samples\n",
        "              anchor_representation = model(anchor_image)\n",
        "              positive_representation = model(positive_image)\n",
        "              negative_representation = model(negative_image)\n",
        "\n",
        "              loss = criterion(anchor_representation, positive_representation, negative_representation)\n",
        "              print(loss)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              train_losses.append(loss/triplet_dataloader.batch_size)\n",
        "      \n",
        "    fig, (ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax1.plot(train_losses, label='train')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    plt.show()  \n",
        "    return model,train_losses\n",
        "\n",
        "# get the model\n",
        "import torchvision\n",
        "# model = resnet50(pretrained=True)\n",
        "model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/Intro_to_Deep_Learning/checkpoints_resnet50_test2/ckpt-275.pk'))\n",
        "\n",
        "# batch_size = 32\n",
        "# train_loader, val_loader, test_loader = get_data_loaders(train_data,val_data,test_data,batch_size)\n",
        "\n",
        "num_epochs = 50\n",
        "optimizer = torch.optim.Adam(lr = 0.0001,params=model.parameters(), weight_decay = 1e-4)\n",
        "\n",
        "\n",
        "# Define the triplet margin loss\n",
        "triplet_loss = torch.nn.TripletMarginLoss(margin=1.0)\n",
        "trained_model1, train_losses = train_siamese(model, \n",
        "                               triplet_dataloader1, \n",
        "                               optimizer, \n",
        "                               triplet_loss, \n",
        "                               num_epochs, \n",
        "                               checkpoint_path='/content/drive/MyDrive/Intro_to_Deep_Learning/checkpoints_eff_contrastive/ckpt-{}.pk')\n"
      ],
      "metadata": {
        "id": "XWY15E91p4GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = trained_model.to(device)\n",
        "# Add a new linear layer as classifier\n",
        "trained_model.add_module('classifier', nn.Linear(1280, 196))\n",
        "\n",
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = get_data_loaders(train_data,val_data,test_data,batch_size)\n",
        "\n",
        "\n",
        "num_epochs = 200\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lr = 0.0001,params=trained_model.parameters(), weight_decay = 1e-4)\n",
        "\n",
        "info = train(trained_model,\n",
        "             train_loader,\n",
        "             val_loader,\n",
        "             num_epochs,\n",
        "             criterion,\n",
        "             optimizer,\n",
        "             grad_clip = 0.5,\n",
        "             checkpoint_path='/content/drive/MyDrive/Intro_to_Deep_Learning/checkpoints_resnet50_test2/ckpt-{}.pk')"
      ],
      "metadata": {
        "id": "b27HoGfzt3qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52JrMvklx2hK"
      },
      "outputs": [],
      "source": [
        "# get the model\n",
        "import torchvision\n",
        "# model = resnet50(pretrained=True)\n",
        "model = torchvision.models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "# Add a new linear layer as classifier\n",
        "model.add_module('classifier', nn.Linear(1280, 196))\n",
        "\n",
        "# model.fc = nn.Sequential(nn.Linear(in_features=2048, out_features=500, bias=True),\n",
        "                        #  nn.ReLU(),\n",
        "                        #  nn.Linear(in_features=500, out_features=196, bias=True)) \n",
        "if torch.cuda.is_available():\n",
        "    model = model.to(device)\n",
        "# model.load_state_dict(torch.load('/content/drive/MyDrive/Intro_to_Deep_Learning/checkpoints_resnet50_test2/ckpt-275.pk'))\n",
        "\n",
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = get_data_loaders(train_data,val_data,test_data,batch_size)\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lr = 0.0001,params=model.parameters(), weight_decay = 1e-4)\n",
        "info = train(model,\n",
        "             train_loader,\n",
        "             val_loader,\n",
        "             num_epochs,\n",
        "             criterion,\n",
        "             optimizer,\n",
        "             grad_clip = 0.5,\n",
        "             checkpoint_path='/content/drive/MyDrive/Intro_to_Deep_Learning/checkpoints_resnet50_test2/ckpt-{}.pk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OUsa_1dr3hj"
      },
      "outputs": [],
      "source": [
        "# we can take only part of the dataset \n",
        "\n",
        "# samp = torch.utils.data.Subset(train_data,[0,1,2,3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab7Oqttxg8Vz"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = get_data_loaders(train_data,val_data,test_data,batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-XfqiBbzMK4"
      },
      "outputs": [],
      "source": [
        "\n",
        "num_epochs = 100\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lr = 0.0001,params=model.parameters(), weight_decay = 1e-4)\n",
        "info = train(model, train_loader, val_loader, num_epochs, criterion, optimizer, grad_clip = 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO11_3mVkafk"
      },
      "source": [
        "Try to make the data more diverse with random crops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8D_LBa0kUGm"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(lr = 0.0001,params=model.parameters(), weight_decay = 1e-4)\n",
        "info2 = train(model, train_loader, val_loader, num_epochs, criterion, optimizer, grad_clip = 0.5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}